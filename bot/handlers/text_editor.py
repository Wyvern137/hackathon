"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞
"""
import logging
from telegram import Update
from telegram.ext import ContextTypes, ConversationHandler, MessageHandler, CallbackQueryHandler, filters
from bot.services.ai.openrouter import openrouter_api
from bot.services.content.text_processor import (
    text_processor,
    analyze_target_audience,
    suggest_seo_improvements,
    suggest_structure,
    compare_texts,
    check_tonality
)
from bot.services.content.style_checker import style_checker
from bot.utils.helpers import get_or_create_user
from bot.database.models import ContentHistory, NKOProfile
from bot.database.database import get_db
from bot.keyboards.inline import get_text_editor_actions_keyboard
from bot.keyboards.main_menu import get_main_menu_keyboard

logger = logging.getLogger(__name__)


async def show_text_editor_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–µ–Ω—é —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞"""
    text = (
        "‚úèÔ∏è **–†–µ–¥–∞–∫—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞**\n\n"
        "–û—Ç–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –Ø –ø—Ä–æ–≤–µ—Ä—é –µ–≥–æ –Ω–∞:\n"
        "‚Ä¢ –û—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏\n"
        "‚Ä¢ –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏\n"
        "‚Ä¢ –°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –Ω–µ–¥–æ—á–µ—Ç—ã\n"
        "‚Ä¢ –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è\n\n"
        "–ò –ø—Ä–µ–¥–ª–æ–∂—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é."
    )
    
    await update.message.reply_text(text, parse_mode="Markdown")
    return "waiting_text"


async def handle_text_for_editing(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    text = update.message.text
    
    if not text or len(text.strip()) < 10:
        await update.message.reply_text(
            "‚ùå –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –ù–∞–ø–∏—à–∏ —Ö–æ—Ç—è –±—ã 10 —Å–∏–º–≤–æ–ª–æ–≤:"
        )
        return "waiting_text"
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –æ–±—Ä–∞–±–æ—Ç–∫–µ
    processing_msg = await update.message.reply_text("‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–µ–∫—Å—Ç...")
    
    try:
        user_id = update.effective_user.id
        get_or_create_user(user_id, update.effective_user.username, update.effective_user.first_name or "")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ù–ö–û –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∏–ª—è
        nko_profile = None
        with get_db() as db:
            profile = db.query(NKOProfile).filter(NKOProfile.user_id == user_id).first()
            if profile:
                nko_profile = profile
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
        readability = text_processor.calculate_readability(text)
        sentiment = text_processor.analyze_sentiment(text)
        repetitions = text_processor.check_repetitions(text)
        length_check = text_processor.check_length_for_format(text, "post")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∏–ª—é –ù–ö–û (–µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ—Ñ–∏–ª—å)
        style_check = None
        if nko_profile and nko_profile.is_complete:
            style_check = await style_checker.check_style(text, nko_profile)
        
        # –ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ—Ñ–∏–ª—å)
        audience_analysis = None
        if nko_profile and nko_profile.target_audience:
            audience_analysis = await analyze_target_audience(text, nko_profile.target_audience)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å —É—á–µ—Ç–æ–º –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
        style_info = ""
        if style_check:
            style_info = f"\n–°—Ç–∏–ª—å –ù–ö–û: {nko_profile.tone_of_voice}\n"
            style_info += f"–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∏–ª—è: {'–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç' if style_check.get('matches_style') else '–ù–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç'}\n"
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ –¥–ª—è —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ –∏—Å–ø—Ä–∞–≤—å –µ–≥–æ:

{text}
{style_info}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:
1. –û—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
2. –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
3. –ü—É–Ω–∫—Ç—É–∞—Ü–∏–æ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
4. –°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –Ω–µ–¥–æ—á–µ—Ç—ã
5. –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
6. –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
7. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∏–ª—é –ù–ö–û (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ –≤—ã—à–µ)

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å:
1. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
2. –°–ø–∏—Å–æ–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π —Å –ø–æ—è—Å–Ω–µ–Ω–∏—è–º–∏
3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Ç–µ–∫—Å—Ç–∞
4. –û—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–∞ (1-10)

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –¢–ï–ö–°–¢:
[–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç]

–ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
- [–æ–ø–∏—Å–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è 1]
- [–æ–ø–∏—Å–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è 2]

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
- [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 1]
- [—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 2]

–û–¶–ï–ù–ö–ê: [–æ—Ü–µ–Ω–∫–∞]/10"""
        
        result = await openrouter_api.generate_text(
            prompt=prompt,
            system_prompt="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—é —Ç–µ–∫—Å—Ç–æ–≤ –∏ –∫–æ—Ä—Ä–µ–∫—Ç—É—Ä–µ.",
            temperature=0.3,
            max_tokens=800
        )
        
        if result and result.get("success"):
            edited_content = result.get("content", "")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
            report = f"‚úÖ **–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!**\n\n"
            report += f"**–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:**\n{edited_content}\n\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            report += "**üìä –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞:**\n"
            report += f"‚Ä¢ –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å: {readability.get('readability_level', '–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ')}\n"
            report += f"‚Ä¢ –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {sentiment.get('tonality', '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π')}\n"
            report += f"‚Ä¢ –î–ª–∏–Ω–∞: {length_check['length']} —Å–∏–º–≤–æ–ª–æ–≤ ({length_check['word_count']} —Å–ª–æ–≤)\n"
            report += f"‚Ä¢ {length_check['recommendation']}\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è—Ö
            if repetitions.get("repeated_words") or repetitions.get("repeated_phrases"):
                report += "\n**‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è:**\n"
                if repetitions.get("repeated_words"):
                    top_word = max(repetitions["repeated_words"].items(), key=lambda x: x[1])
                    report += f"‚Ä¢ –°–ª–æ–≤–æ '{top_word[0]}' –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è {top_word[1]} —Ä–∞–∑\n"
                if repetitions.get("repeated_phrases"):
                    top_phrase = max(repetitions["repeated_phrases"].items(), key=lambda x: x[1])
                    report += f"‚Ä¢ –§—Ä–∞–∑–∞ '{top_phrase[0]}' –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è {top_phrase[1]} —Ä–∞–∑\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Å—Ç–∏–ª—è –ù–ö–û
            if style_check:
                if style_check.get("matches_style"):
                    report += "\n‚úÖ –¢–µ–∫—Å—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∏–ª—é –ù–ö–û\n"
                else:
                    report += "\n‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∏–ª—é –ù–ö–û\n"
                    if style_check.get("recommendations"):
                        for rec in style_check["recommendations"][:3]:
                            report += f"‚Ä¢ {rec}\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ –∞—É–¥–∏—Ç–æ—Ä–∏–∏
            if audience_analysis:
                if audience_analysis.get("fits_audience"):
                    report += f"\n‚úÖ –¢–µ–∫—Å—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏ ({audience_analysis.get('score', 7)}/10)\n"
                else:
                    report += f"\n‚ö†Ô∏è –¢–µ–∫—Å—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —É–ª—É—á—à–µ–Ω –¥–ª—è –∞—É–¥–∏—Ç–æ—Ä–∏–∏\n"
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            with get_db() as db:
                history_entry = ContentHistory(
                    user_id=user_id,
                    content_type="text",
                    content_data={
                        "original_text": text,
                        "edited_text": edited_content,
                        "type": "edited",
                        "readability": readability,
                        "sentiment": sentiment,
                        "repetitions": repetitions,
                        "style_check": style_check,
                        "audience_analysis": audience_analysis
                    }
                )
                db.add(history_entry)
                db.commit()
            
            context.user_data['edited_text'] = edited_content
            context.user_data['original_text'] = text
            context.user_data['analysis_data'] = {
                "readability": readability,
                "sentiment": sentiment,
                "repetitions": repetitions,
                "style_check": style_check,
                "audience_analysis": audience_analysis
            }
            
            await processing_msg.edit_text(
                report,
                reply_markup=get_text_editor_actions_keyboard(),
                parse_mode="Markdown"
            )
            
            return "text_analyzed"
        else:
            await processing_msg.edit_text(
                "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑."
            )
    
    except Exception as e:
        logger.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        await processing_msg.edit_text(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏. –ü–æ–ø—Ä–æ–±—É–π –µ—â–µ —Ä–∞–∑."
        )
    
    from telegram.ext import ConversationHandler
    return ConversationHandler.END


async def text_editor_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ callback-–æ–≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞"""
    query = update.callback_query
    await query.answer()
    
    callback_data = query.data
    analysis_data = context.user_data.get('analysis_data', {})
    edited_text = context.user_data.get('edited_text', '')
    original_text = context.user_data.get('original_text', '')
    
    if callback_data == "editor_seo":
        # –ê–Ω–∞–ª–∏–∑ SEO
        seo_analysis = await suggest_seo_improvements(edited_text)
        
        text = "üîç **SEO –∞–Ω–∞–ª–∏–∑:**\n\n"
        if seo_analysis.get("needs_seo"):
            text += "–†–µ–∫–æ–º–µ–Ω–¥—É—é—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è SEO:\n"
            if seo_analysis.get("keywords_suggestions"):
                text += f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(seo_analysis['keywords_suggestions'][:5])}\n"
            if seo_analysis.get("improvements"):
                text += "\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n"
                for imp in seo_analysis["improvements"][:5]:
                    text += f"‚Ä¢ {imp}\n"
        else:
            text += "–¢–µ–∫—Å—Ç –Ω–µ —Ç—Ä–µ–±—É–µ—Ç SEO-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏."
        
        await query.edit_message_text(text, parse_mode="Markdown")
    
    elif callback_data == "editor_structure":
        # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        structure = await suggest_structure(edited_text)
        
        text = "üìê **–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:**\n\n"
        if structure.get("improvements"):
            text += "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n"
            for imp in structure["improvements"][:5]:
                text += f"‚Ä¢ {imp}\n"
            text += f"\n**–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:**\n{structure.get('formatted_text', edited_text)[:500]}..."
        else:
            text += "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–µ–∫—Å—Ç–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞."
        
        await query.edit_message_text(text, parse_mode="Markdown")
    
    elif callback_data == "editor_tonality":
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        sentiment = analysis_data.get("sentiment", {})
        text = f"üé≠ **–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:**\n\n"
        text += f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {sentiment.get('tonality', '–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π')}\n"
        if sentiment.get("scores"):
            scores = sentiment["scores"]
            text += f"–ü–æ–∑–∏—Ç–∏–≤–Ω–æ—Å—Ç—å: {scores.get('positive', 0):.2f}\n"
            text += f"–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å: {scores.get('neutral', 0):.2f}\n"
            text += f"–ù–µ–≥–∞—Ç–∏–≤–Ω–æ—Å—Ç—å: {scores.get('negative', 0):.2f}\n"
        
        await query.edit_message_text(text, parse_mode="Markdown")
    
    elif callback_data == "editor_readability":
        # –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å
        readability = analysis_data.get("readability", {})
        text = f"üìñ **–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞:**\n\n"
        text += f"–£—Ä–æ–≤–µ–Ω—å: {readability.get('readability_level', '–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ')}\n"
        if readability.get("readability_score") is not None:
            text += f"–ë–∞–ª–ª: {readability['readability_score']}/100\n"
        text += f"–°–ª–æ–≤: {readability.get('word_count', 0)}\n"
        text += f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {readability.get('sentence_count', 0)}\n"
        text += f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {readability.get('avg_sentence_length', 0):.1f} —Å–ª–æ–≤"
        
        await query.edit_message_text(text, parse_mode="Markdown")
    
    elif callback_data == "editor_repetitions":
        # –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
        repetitions = analysis_data.get("repetitions", {})
        text = "üîÑ **–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π:**\n\n"
        
        if repetitions.get("repeated_words") or repetitions.get("repeated_phrases"):
            if repetitions.get("repeated_words"):
                text += "–ß–∞—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–ª–æ–≤–∞:\n"
                for word, count in list(repetitions["repeated_words"].items())[:5]:
                    text += f"‚Ä¢ '{word}': {count} —Ä–∞–∑\n"
            
            if repetitions.get("repeated_phrases"):
                text += "\n–ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ñ—Ä–∞–∑—ã:\n"
                for phrase, count in list(repetitions["repeated_phrases"].items())[:3]:
                    text += f"‚Ä¢ '{phrase}': {count} —Ä–∞–∑\n"
            
            if repetitions.get("suggestions"):
                text += "\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n"
                for sug in repetitions["suggestions"][:3]:
                    text += f"‚Ä¢ {sug}\n"
        else:
            text += "‚úÖ –ü–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Å–ª–æ–≤ –∏ —Ñ—Ä–∞–∑ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ."
        
        await query.edit_message_text(text, parse_mode="Markdown")
    
    elif callback_data == "editor_stories":
        # Stories-–≤–µ—Ä—Å–∏—è
        stories_text = text_processor.generate_stories_version(edited_text)
        text = f"üì± **–í–µ—Ä—Å–∏—è –¥–ª—è Stories:**\n\n{stories_text}"
        
        await query.edit_message_text(text, parse_mode="Markdown")
    
    return "text_analyzed"


def setup_text_editor_handlers(application):
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞"""
    conv_handler = ConversationHandler(
        entry_points=[
            MessageHandler(filters.Regex("^‚úèÔ∏è –†–µ–¥–∞–∫—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞$"), show_text_editor_menu),
        ],
        states={
            "waiting_text": [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text_for_editing)
            ],
            "text_analyzed": [
                CallbackQueryHandler(text_editor_callback, pattern="^editor_")
            ]
        },
        fallbacks=[
            MessageHandler(filters.Regex("^‚ùå –û—Ç–º–µ–Ω–∞$"), lambda u, c: ConversationHandler.END),
            MessageHandler(filters.Regex("^‚óÄÔ∏è –ù–∞–∑–∞–¥$"), lambda u, c: ConversationHandler.END),
        ],
        allow_reentry=True
    )
    
    application.add_handler(conv_handler)

